{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 39
   },
   "source": [
    "### 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": 1
   },
   "outputs": [],
   "source": [
    "from utils import load_corpus_bert\n",
    "\n",
    "TRAIN_PATH = \"./data/weibo2018/train.txt\"\n",
    "TEST_PATH = \"./data/weibo2018/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 3
   },
   "outputs": [],
   "source": [
    "# 分别加载训练集和测试集\n",
    "train_data = load_corpus_bert(TRAIN_PATH)\n",
    "test_data = load_corpus_bert(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 4
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  label\n0    “书中自有黄金屋，书中自有颜如玉”。沿着岁月的长河跋涉，或是风光旖旎，或是姹紫嫣红，万千...      1\n1  这是英超被黑的最惨的一次[二哈][二哈]十几年来，中国只有孙继海，董方卓，郑智，李铁登陆过英...      0\n2   中国远洋海运集团副总经理俞曾港4月21日在 上表示，中央企业“走出去”是要站在更高的平台参...      1\n3  看《流星花园》其实也还好啦，现在的观念以及时尚眼光都不一样了，或许十几年之后的人看我们的现在...      1\n4  汉武帝的罪己诏的真实性尽管存在着争议，然而“轮台罪己诏”作为中国历史上第一份皇帝自我批评的文...      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>“书中自有黄金屋，书中自有颜如玉”。沿着岁月的长河跋涉，或是风光旖旎，或是姹紫嫣红，万千...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>这是英超被黑的最惨的一次[二哈][二哈]十几年来，中国只有孙继海，董方卓，郑智，李铁登陆过英...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>中国远洋海运集团副总经理俞曾港4月21日在 上表示，中央企业“走出去”是要站在更高的平台参...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>看《流星花园》其实也还好啦，现在的观念以及时尚眼光都不一样了，或许十几年之后的人看我们的现在...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>汉武帝的罪己诏的真实性尽管存在着争议，然而“轮台罪己诏”作为中国历史上第一份皇帝自我批评的文...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.DataFrame(train_data, columns=[\"text\", \"label\"])\n",
    "df_test = pd.DataFrame(test_data, columns=[\"text\", \"label\"])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 41
   },
   "source": [
    "### 加载Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": 5
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kshao/Desktop/weibo-crawler-master/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"    # 在我的电脑上不加这一句, bert模型会报错\n",
    "MODEL_PATH = \"./model/chinese_wwm_pytorch\"     # 下载地址见 https://github.com/ymcui/Chinese-BERT-wwm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": 6
   },
   "outputs": [],
   "source": [
    "# 加载\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)   # 分词器\n",
    "bert = BertModel.from_pretrained(MODEL_PATH)            # 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 43
   },
   "source": [
    "### 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": 7
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": 8
   },
   "outputs": [],
   "source": [
    "# 超参数\n",
    "learning_rate = 1e-3\n",
    "input_size = 768\n",
    "num_epoches = 10\n",
    "batch_size = 100\n",
    "decay_rate = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": 9
   },
   "outputs": [],
   "source": [
    "# 数据集\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.data = df[\"text\"].tolist()\n",
    "        self.label = df[\"label\"].tolist()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.label[index]\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "# 训练集\n",
    "train_data = MyDataset(df_train)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 测试集\n",
    "test_data = MyDataset(df_test)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": 10
   },
   "outputs": [],
   "source": [
    "# 网络结构\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "net = Net(input_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": 34
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# 测试集效果检验\n",
    "def test():\n",
    "    y_pred, y_true = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for words, labels in test_loader:\n",
    "            tokens = tokenizer(words, padding=True)\n",
    "            input_ids = torch.tensor(tokens[\"input_ids\"]).to(device)\n",
    "            attention_mask = torch.tensor(tokens[\"attention_mask\"]).to(device)\n",
    "            last_hidden_states = bert(input_ids, attention_mask=attention_mask)\n",
    "            bert_output = last_hidden_states[0][:, 0]\n",
    "            outputs = net(bert_output)          # 前向传播\n",
    "            outputs = outputs.view(-1)          # 将输出展平\n",
    "            y_pred.append(outputs)\n",
    "            y_true.append(labels)\n",
    "\n",
    "    y_prob = torch.cat(y_pred)\n",
    "    y_true = torch.cat(y_true)\n",
    "    y_pred = y_prob.clone()\n",
    "    y_pred[y_pred > 0.5] = 1\n",
    "    y_pred[y_pred <= 0.5] = 0\n",
    "    \n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    print(\"准确率:\", metrics.accuracy_score(y_true, y_pred))\n",
    "    print(\"AUC:\", metrics.roc_auc_score(y_true, y_prob) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": 11
   },
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": 14,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, step:10, loss:0.6677583456039429\n",
      "epoch:1, step:20, loss:0.6224325895309448\n",
      "epoch:1, step:30, loss:0.59061598777771\n",
      "epoch:1, step:40, loss:0.5714761018753052\n",
      "epoch:1, step:50, loss:0.5388660430908203\n",
      "epoch:1, step:60, loss:0.5223734974861145\n",
      "epoch:1, step:70, loss:0.503071665763855\n",
      "epoch:1, step:80, loss:0.4793769419193268\n",
      "epoch:1, step:90, loss:0.4926925301551819\n",
      "epoch:1, step:100, loss:0.5060964822769165\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.75       155\n",
      "           1       0.91      0.85      0.88       345\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.81      0.83      0.82       500\n",
      "weighted avg       0.84      0.84      0.84       500\n",
      "\n",
      "准确率: 0.836\n",
      "AUC: 0.8975409069658719\n",
      "saved model:  ./model/bert_dnn_1.model\n",
      "epoch:2, step:10, loss:0.46593743562698364\n",
      "epoch:2, step:20, loss:0.47394171357154846\n",
      "epoch:2, step:30, loss:0.4775104522705078\n",
      "epoch:2, step:40, loss:0.45959049463272095\n",
      "epoch:2, step:50, loss:0.4646008610725403\n",
      "epoch:2, step:60, loss:0.4353228211402893\n",
      "epoch:2, step:70, loss:0.45806145668029785\n",
      "epoch:2, step:80, loss:0.4425559639930725\n",
      "epoch:2, step:90, loss:0.4671564996242523\n",
      "epoch:2, step:100, loss:0.42506280541419983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.75      0.76       155\n",
      "           1       0.89      0.90      0.89       345\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.83      0.82      0.83       500\n",
      "weighted avg       0.85      0.85      0.85       500\n",
      "\n",
      "准确率: 0.854\n",
      "AUC: 0.9101449275362319\n",
      "saved model:  ./model/bert_dnn_2.model\n",
      "epoch:3, step:10, loss:0.4449755549430847\n",
      "epoch:3, step:20, loss:0.43090277910232544\n",
      "epoch:3, step:30, loss:0.41294407844543457\n",
      "epoch:3, step:40, loss:0.4801834225654602\n",
      "epoch:3, step:50, loss:0.4254514276981354\n",
      "epoch:3, step:60, loss:0.43366900086402893\n",
      "epoch:3, step:70, loss:0.4407181739807129\n",
      "epoch:3, step:80, loss:0.4278442859649658\n",
      "epoch:3, step:90, loss:0.4466795325279236\n",
      "epoch:3, step:100, loss:0.40197834372520447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77       155\n",
      "           1       0.91      0.88      0.89       345\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.82      0.84      0.83       500\n",
      "weighted avg       0.86      0.85      0.85       500\n",
      "\n",
      "准确率: 0.852\n",
      "AUC: 0.9159794296400187\n",
      "saved model:  ./model/bert_dnn_3.model\n",
      "epoch:4, step:10, loss:0.4288552403450012\n",
      "epoch:4, step:20, loss:0.4520801901817322\n",
      "epoch:4, step:30, loss:0.4288322925567627\n",
      "epoch:4, step:40, loss:0.4209361672401428\n",
      "epoch:4, step:50, loss:0.4307454526424408\n",
      "epoch:4, step:60, loss:0.40228599309921265\n",
      "epoch:4, step:70, loss:0.4304620325565338\n",
      "epoch:4, step:80, loss:0.4140836298465729\n",
      "epoch:4, step:90, loss:0.41040587425231934\n",
      "epoch:4, step:100, loss:0.41667428612709045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77       155\n",
      "           1       0.91      0.87      0.89       345\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.82      0.84      0.83       500\n",
      "weighted avg       0.86      0.85      0.85       500\n",
      "\n",
      "准确率: 0.852\n",
      "AUC: 0.9196820944366527\n",
      "saved model:  ./model/bert_dnn_4.model\n",
      "epoch:5, step:10, loss:0.4410246014595032\n",
      "epoch:5, step:20, loss:0.40738382935523987\n",
      "epoch:5, step:30, loss:0.3900151550769806\n",
      "epoch:5, step:40, loss:0.422016441822052\n",
      "epoch:5, step:50, loss:0.4280427098274231\n",
      "epoch:5, step:60, loss:0.39279666543006897\n",
      "epoch:5, step:70, loss:0.42276692390441895\n",
      "epoch:5, step:80, loss:0.4254140257835388\n",
      "epoch:5, step:90, loss:0.4182881712913513\n",
      "epoch:5, step:100, loss:0.40931764245033264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.77       155\n",
      "           1       0.91      0.88      0.89       345\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.83      0.84      0.83       500\n",
      "weighted avg       0.86      0.85      0.86       500\n",
      "\n",
      "准确率: 0.854\n",
      "AUC: 0.9219635343618514\n",
      "saved model:  ./model/bert_dnn_5.model\n",
      "epoch:6, step:10, loss:0.43421250581741333\n",
      "epoch:6, step:20, loss:0.4062782824039459\n",
      "epoch:6, step:30, loss:0.3832527995109558\n",
      "epoch:6, step:40, loss:0.3770297169685364\n",
      "epoch:6, step:50, loss:0.43163618445396423\n",
      "epoch:6, step:60, loss:0.413491427898407\n",
      "epoch:6, step:70, loss:0.414107084274292\n",
      "epoch:6, step:80, loss:0.4207425117492676\n",
      "epoch:6, step:90, loss:0.42970284819602966\n",
      "epoch:6, step:100, loss:0.398442804813385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78       155\n",
      "           1       0.91      0.88      0.89       345\n",
      "\n",
      "    accuracy                           0.86       500\n",
      "   macro avg       0.83      0.84      0.84       500\n",
      "weighted avg       0.86      0.86      0.86       500\n",
      "\n",
      "准确率: 0.856\n",
      "AUC: 0.923291257597008\n",
      "saved model:  ./model/bert_dnn_6.model\n",
      "epoch:7, step:10, loss:0.444036066532135\n",
      "epoch:7, step:20, loss:0.404975950717926\n",
      "epoch:7, step:30, loss:0.4274110198020935\n",
      "epoch:7, step:40, loss:0.3870013654232025\n",
      "epoch:7, step:50, loss:0.4251241683959961\n",
      "epoch:7, step:60, loss:0.40662914514541626\n",
      "epoch:7, step:70, loss:0.40749794244766235\n",
      "epoch:7, step:80, loss:0.3831399083137512\n",
      "epoch:7, step:90, loss:0.3985605835914612\n",
      "epoch:7, step:100, loss:0.3878958523273468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78       155\n",
      "           1       0.92      0.87      0.89       345\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.83      0.85      0.83       500\n",
      "weighted avg       0.86      0.85      0.86       500\n",
      "\n",
      "准确率: 0.854\n",
      "AUC: 0.9249742870500235\n",
      "saved model:  ./model/bert_dnn_7.model\n",
      "epoch:8, step:10, loss:0.38708609342575073\n",
      "epoch:8, step:20, loss:0.3995457589626312\n",
      "epoch:8, step:30, loss:0.4092056155204773\n",
      "epoch:8, step:40, loss:0.4056014120578766\n",
      "epoch:8, step:50, loss:0.4078908860683441\n",
      "epoch:8, step:60, loss:0.3966495096683502\n",
      "epoch:8, step:70, loss:0.4009708762168884\n",
      "epoch:8, step:80, loss:0.42385631799697876\n",
      "epoch:8, step:90, loss:0.4064720571041107\n",
      "epoch:8, step:100, loss:0.40995827317237854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.82      0.78       155\n",
      "           1       0.91      0.87      0.89       345\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.83      0.84      0.83       500\n",
      "weighted avg       0.86      0.85      0.86       500\n",
      "\n",
      "准确率: 0.854\n",
      "AUC: 0.9264516129032259\n",
      "saved model:  ./model/bert_dnn_8.model\n",
      "epoch:9, step:10, loss:0.388742059469223\n",
      "epoch:9, step:20, loss:0.3978211283683777\n",
      "epoch:9, step:30, loss:0.4065127968788147\n",
      "epoch:9, step:40, loss:0.39211076498031616\n",
      "epoch:9, step:50, loss:0.41840487718582153\n",
      "epoch:9, step:60, loss:0.413806676864624\n",
      "epoch:9, step:70, loss:0.4313274919986725\n",
      "epoch:9, step:80, loss:0.3939538300037384\n",
      "epoch:9, step:90, loss:0.3910176157951355\n",
      "epoch:9, step:100, loss:0.3961030840873718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78       155\n",
      "           1       0.92      0.88      0.89       345\n",
      "\n",
      "    accuracy                           0.86       500\n",
      "   macro avg       0.83      0.85      0.84       500\n",
      "weighted avg       0.86      0.86      0.86       500\n",
      "\n",
      "准确率: 0.858\n",
      "AUC: 0.9271622253389434\n",
      "saved model:  ./model/bert_dnn_9.model\n",
      "epoch:10, step:10, loss:0.4006810188293457\n",
      "epoch:10, step:20, loss:0.4103207588195801\n",
      "epoch:10, step:30, loss:0.3888043761253357\n",
      "epoch:10, step:40, loss:0.3990044891834259\n",
      "epoch:10, step:50, loss:0.38681960105895996\n",
      "epoch:10, step:60, loss:0.447637140750885\n",
      "epoch:10, step:70, loss:0.407050758600235\n",
      "epoch:10, step:80, loss:0.3983752131462097\n",
      "epoch:10, step:90, loss:0.4043295979499817\n",
      "epoch:10, step:100, loss:0.3624148368835449\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.78       155\n",
      "           1       0.93      0.86      0.89       345\n",
      "\n",
      "    accuracy                           0.85       500\n",
      "   macro avg       0.83      0.85      0.84       500\n",
      "weighted avg       0.86      0.85      0.86       500\n",
      "\n",
      "准确率: 0.854\n",
      "AUC: 0.9275923328658252\n",
      "saved model:  ./model/bert_dnn_10.model\n"
     ]
    }
   ],
   "source": [
    "# 迭代训练\n",
    "for epoch in range(num_epoches):\n",
    "    total_loss = 0\n",
    "    for i, (words, labels) in enumerate(train_loader):\n",
    "        tokens = tokenizer(words, padding=True)\n",
    "        input_ids = torch.tensor(tokens[\"input_ids\"]).to(device)\n",
    "        attention_mask = torch.tensor(tokens[\"attention_mask\"]).to(device)\n",
    "        labels = labels.float().to(device)\n",
    "        with torch.no_grad():\n",
    "            last_hidden_states = bert(input_ids, attention_mask=attention_mask)\n",
    "            bert_output = last_hidden_states[0][:, 0]\n",
    "        optimizer.zero_grad()               # 梯度清零\n",
    "        outputs = net(bert_output)          # 前向传播\n",
    "        logits = outputs.view(-1)           # 将输出展平\n",
    "        loss = criterion(logits, labels)    # loss计算\n",
    "        total_loss += loss\n",
    "        loss.backward()                     # 反向传播，计算梯度\n",
    "        optimizer.step()                    # 梯度更新\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(\"epoch:{}, step:{}, loss:{}\".format(epoch+1, i+1, total_loss/10))\n",
    "            total_loss = 0\n",
    "    \n",
    "    # learning_rate decay\n",
    "    scheduler.step()\n",
    "    \n",
    "    # test\n",
    "    test()\n",
    "    \n",
    "    # save model\n",
    "    model_path = \"./model/bert_dnn_{}.model\".format(epoch+1)\n",
    "    torch.save(net, model_path)\n",
    "    print(\"saved model: \", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": 23
   },
   "source": [
    "### 输入句子，判断情感倾向（1正/0负）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": 38
   },
   "outputs": [],
   "source": [
    "net = torch.load(\"./model/bert_dnn_10.model\")    # 训练过程中的巅峰时刻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy\n",
    "import re\n",
    "import string"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "1874"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/kshao/Desktop/weibo-crawler-master/weibo-search-master/结果文件/花西子/花西子9-10.csv')\n",
    "res = []\n",
    "# for val in data[\"comment_content\"].values:\n",
    "# for val in data[\"text\"].values:\n",
    "\n",
    "for val in data[\"微博正文\"].values:\n",
    "    # 去除特殊字符\n",
    "    if type(val) != str:\n",
    "        val = str(val)\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', val)\n",
    "    # 转换为小写\n",
    "    cleaned_text = cleaned_text.lower()\n",
    "    res.append(cleaned_text)\n",
    "    # tmp = BeautifulSoup(val,'html.parser').get_text()\n",
    "    # if tmp != '':\n",
    "    #     res.append(tmp)\n",
    "len(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "res_1 = res[:512]\n",
    "res_2 = res[512:1024]\n",
    "res_3 = res[1024: 1536]\n",
    "res_4 = res[1536:]\n",
    "# res_4 = res[1536:2048]\n",
    "# res_5 = res[2048:2560]\n",
    "# res_6 = res[2560:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": 37
   },
   "outputs": [],
   "source": [
    "s = res_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tokens = tokenizer(s, padding=True)\n",
    "input_ids = torch.tensor(tokens[\"input_ids\"])\n",
    "attention_mask = torch.tensor(tokens[\"attention_mask\"])\n",
    "last_hidden_states = bert(input_ids, attention_mask=attention_mask)\n",
    "bert_output = last_hidden_states[0][:, 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "outputs = net(bert_output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "res_l = []"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "cell_id": 32
   },
   "outputs": [],
   "source": [
    "for v in outputs:\n",
    "    res_l.append(float(v.detach()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 238\n"
     ]
    }
   ],
   "source": [
    "pos = 0\n",
    "imp = 0\n",
    "for v in res_l:\n",
    "    if v > 0.5:\n",
    "        pos += 1\n",
    "    else:\n",
    "        imp += 1\n",
    "print(pos,imp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5509433962264151"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos / (pos + imp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "max_cell_id": 45
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
